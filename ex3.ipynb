{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE 3:\n",
    "\n",
    "***Neural Networks and Gaussian process:***\n",
    "Predict the SP500 with the â€€nancial indicators assigned to your team in the google spreadsheet (ep, dp, de, dy, dfy, bm, svar, ntis, in, tbl , see RLab3 2 GWcausalSP500.R), some lagged series of these indicators and lags of the target using a Neural Network and a GP regression with your desired kernel. Predict return, or price, or direction (up or down). For which target works best? Do some feature selection to disregard some variables, select appropriate lags: causality, (distance) correlation, VAR-test, Lasso ... (The script RLab5 GausProc.R can be of help. The dataset is goyal-welch2022Monthly.csv and work within the period 1927/2021.)\n",
    "\n",
    "In our case, we have been assigned variables dp, de and ep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INDEX:\n",
    "\n",
    "0. [DATA AND LIBRARY IMPORTS](#0.-DATA-AND-LIBRARY-IMPORTS)\n",
    "\n",
    "1. [PREPROCESSING AND FEATURE ENGINEERING](#1.-PREPROCESSING-AND-FEATURE-ENGINEERING)\n",
    "\n",
    "2. [LAG CREATION AND SELECTION](#2.-LAG-CREATION-AND-SELECTION)\n",
    "\n",
    "3. [ARIMA BASELINE MODEL](#3.-ARIMA-BASELINE-MODEL)\n",
    "\n",
    "4. [NEURAL NETWORK](#4.-NEURAL-NETWORK)\n",
    "\n",
    "5. [GAUSSIAN PROCESS](#5.-GAUSSIAN-PROCESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. DATA AND LIBRARY IMPORTS\n",
    "\n",
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "from statsmodels.tsa.stattools import grangercausalitytests, adfuller, acf, pacf\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pmdarima as pm\n",
    "from pmdarima.model_selection import train_test_split\n",
    "from scipy.stats import chi2\n",
    "from scipy.spatial.distance import correlation\n",
    "import scipy.stats\n",
    "import dcor\n",
    "from sklearn.linear_model import Lasso\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceMetrics:\n",
    "    def __init__(self):\n",
    "        self.metrics = {'R2': [], 'MSE': [], 'RMSE': [], 'MAE': []}\n",
    "        self.set_names = []\n",
    "\n",
    "    def add_metrics(self, y_true, y_pred, name=None):\n",
    "        \"\"\"Add a new set of metrics to the storage with an optional name.\"\"\"\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        \n",
    "        if r2 >= 0:\n",
    "            self.metrics['R2'].append(r2)\n",
    "        else:\n",
    "            self.metrics['R2'].append(0)\n",
    "        self.metrics['MSE'].append(mse)\n",
    "        self.metrics['RMSE'].append(rmse)\n",
    "        self.metrics['MAE'].append(mae)\n",
    "        \n",
    "        if name is None:\n",
    "            name = f\"Set {len(self.set_names) + 1}\"\n",
    "        self.set_names.append(name)\n",
    "        \n",
    "        print(f\"Metrics for {name}:\")\n",
    "        print(\"R2 Score:\", r2)\n",
    "        print(\"Mean Squared Error (MSE):\", mse)\n",
    "        print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "        print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "    def plot_metrics(self):\n",
    "        \"\"\"Plot all metrics in separate bar charts for comparison using set names for labels.\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        n = len(self.metrics['MSE'])\n",
    "        index = np.arange(n)\n",
    "        bar_width = 0.35 \n",
    "        color = 'skyblue'\n",
    "        titles = {'R2': 'R2 Score', 'MSE': 'Mean Squared Error', 'RMSE': 'Root Mean Squared Error', 'MAE': 'Mean Absolute Error'}\n",
    "        fig, axes = plt.subplots(nrows=4, ncols=1, figsize=(6, 18), sharey=True)\n",
    "        for i, (metric_name, values) in enumerate(self.metrics.items()):\n",
    "            axes[i].bar(index, values, bar_width, color=color, label=metric_name)\n",
    "            # axes[i].set_xlabel('Model Set')\n",
    "            axes[i].set_title(titles[metric_name])\n",
    "            axes[i].set_xticks(index)\n",
    "            axes[i].set_xticklabels(self.set_names)\n",
    "            axes[i].legend()\n",
    "        plt.suptitle('Comparison of Performance Metrics')\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelPredictions:\n",
    "    def __init__(self, actual_data):\n",
    "        \"\"\"\n",
    "        Initializes the ModelPredictions class with actual test data.\n",
    "        \n",
    "        Parameters:\n",
    "            actual_data (pd.Series or pd.DataFrame): The actual data points from the test set.\n",
    "        \"\"\"\n",
    "        self.actual_data = actual_data\n",
    "        self.predictions = {}\n",
    "        self.colors = ['red', 'blue', 'magenta', 'orange', 'purple', 'brown', 'pink', 'olive', 'cyan']\n",
    "    \n",
    "    def add_predictions(self, prediction_data, label):\n",
    "        \"\"\"\n",
    "        Stores the prediction data under a specified label.\n",
    "        \n",
    "        Parameters:\n",
    "            prediction_data (pd.Series or pd.DataFrame): The predicted data points.\n",
    "            label (str): The label for the prediction to be used in the plot legend.\n",
    "        \"\"\"\n",
    "        self.predictions[label] = prediction_data\n",
    "    \n",
    "    def plot_predictions(self):\n",
    "        \"\"\"\n",
    "        Plots all stored predictions and the actual data on the same plot.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(self.actual_data, label='Actual Returns', color='black')\n",
    "        colors = iter(self.colors)\n",
    "        for label, prediction in self.predictions.items():\n",
    "            plt.plot(prediction.index, prediction, label=label, color=next(colors))\n",
    "        plt.legend()\n",
    "        plt.title('Comparison of Model Predictions and Actual Data')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some further steps on the way down, we decided to keep the last period from 1921 for now, as it will be useful for havig a first value for the differenced variables straight from the beginning. We will also use the previous periods in order to be able to have some lags for the variables straight from the beginning of 1927.\n",
    "\n",
    "We also decided to keep the data up until the whole 2022 because we will use it to test our models on completely new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp = pd.read_csv('goyal-welch2022Monthly.csv')\n",
    "\n",
    "snp['yyyymm'] = snp['yyyymm'].astype(str)\n",
    "snp['yyyymm'] = pd.to_datetime(snp['yyyymm'], format='%Y%m')\n",
    "snp = snp.loc[(snp['yyyymm'] >= '1921-01-01')]# & (snp['yyyymm'] < '2022-01-01')].reset_index(drop=True)\n",
    "snp['Index'] = snp['Index'].str.replace(',', '').astype(float)\n",
    "\n",
    "display(snp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PREPROCESSING AND FEATURE ENGINEERING\n",
    "\n",
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values and Corrupted Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that THERE ARE NO MISSING VALUES FOR OUR VARIABLES OF INTEREST (Index, D12 and E12)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the new features as we need to compute:\n",
    "\n",
    "- Dividend Price Ratio (DP)\n",
    "- Dividend Earnings Ratio (DE)\n",
    "- Earnings Price Ratio (EP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp = snp[['yyyymm', 'Index', 'D12', 'E12']]\n",
    "\n",
    "snp['LogReturns'] = np.log(snp['Index']).diff()\n",
    "snp['PriceDiv'] = snp['Index'] + snp['D12']\n",
    "snp['LogReturnsDiv'] = np.log(snp['PriceDiv']).diff()\n",
    "\n",
    "# We need to fill the NaN values with 0 because the ADF test doesn't tolerate NaN values and we might still need to further differentiate the series.\n",
    "snp.fillna({'LogReturns': 0}, inplace=True)\n",
    "snp.fillna({'LogReturnsDiv': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp['DP'] = np.log(snp['D12']) - np.log(snp['Index'])\n",
    "snp['DE'] = np.log(snp['D12']) - np.log(snp['E12'])\n",
    "snp['EP'] = np.log(snp['E12']) - np.log(snp['Index'])\n",
    "\n",
    "display(snp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationarity and Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=9, ncols=1, figsize=(10, 18))\n",
    "\n",
    "columns_to_plot = ['Index', 'PriceDiv', 'D12', 'E12', 'LogReturns', 'LogReturnsDiv', 'DP', 'DE', 'EP']\n",
    "for i, col in enumerate(columns_to_plot):\n",
    "    axes[i].plot(snp['yyyymm'], snp[col], marker='', linestyle='-')\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel('Date')\n",
    "    axes[i].set_ylabel(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We test for stationarity in the data\n",
    "\n",
    "for col in columns_to_plot:\n",
    "    adf_result = adfuller(snp[col])\n",
    "    print(f'ADF Statistic for {col}: {adf_result[0]}')\n",
    "    print(f'p-value for {col}: {adf_result[1]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables we are interested in are mostly stationary but there are a couple that should be further differenced in order to make them stationary.\n",
    "\n",
    "That being, said, log returns and log returns + dividends are already quite surely stationary so we're not going to bother with their stationarity anymore.\n",
    "\n",
    "Additionally, in further boxplots we have been able to see that variables DE and EP are quite skewed so, even if they are already decently stationary, we will also difference them in order to center them a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp['DP'] = snp['DP'].diff()\n",
    "snp['DE'] = snp['DE'].diff()\n",
    "snp['EP'] = snp['EP'].diff()\n",
    "\n",
    "display(snp.head())\n",
    "\n",
    "# We can safely remove the first row now instead of filling it with 0\n",
    "snp.dropna(axis = 0, inplace = True)\n",
    "\n",
    "display(snp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(10, 6))\n",
    "\n",
    "columns_to_plot = ['DP', 'DE', 'EP']\n",
    "for i, col in enumerate(columns_to_plot):\n",
    "    axes[i].plot(snp['yyyymm'], snp[col], marker='', linestyle='-')\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel('Date')\n",
    "    axes[i].set_ylabel(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# We test again for stationarity in the data\n",
    "\n",
    "for col in columns_to_plot:\n",
    "    adf_result = adfuller(snp[col])\n",
    "    print(f'ADF Statistic for {col}: {adf_result[0]}')\n",
    "    print(f'p-value for {col}: {adf_result[1]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how now our data is completely stationary and we may proceed. Careful attention to the outliers will be needed, though, as they are very specific to the 2008 crisis. We will first standardize the data and afterwards, if there are still outliers, we will treat them or maybe consider scaling with robust scaling (i.e. taking away the median instead of the mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_plot = ['LogReturns', 'LogReturnsDiv', 'DP', 'DE', 'EP']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(15, 10))\n",
    "for i, col in enumerate(columns_to_plot):\n",
    "    sns.boxplot(y=col, data=snp, ax=axes[i])\n",
    "    axes[i].set_title(f'Boxplot of {col}', fontsize=12)\n",
    "    axes[i].tick_params(axis='y', labelsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "snp_std = snp.copy()\n",
    "\n",
    "for col in columns_to_plot:\n",
    "    snp_std[col] = robust_scaler.fit_transform(snp_std[[col]])\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(15, 10))\n",
    "for i, col in enumerate(columns_to_plot):\n",
    "    sns.boxplot(y=col, data=snp, ax=axes[i])\n",
    "    axes[i].set_title(f'Boxplot of {col}', fontsize=12)\n",
    "    axes[i].tick_params(axis='y', labelsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe, the scaled version, even with the robust scaler, returns ranges which are still bigger than the range from the previous version. Even with the outliers we had, as we had already applied a logarithmic transformation to the data, the outliers were not excessively far away from the center, with the exception of the DE and EP ratios.\n",
    "\n",
    "What we will do is \"manually\" transform the data which is bigger than 0.3 in the five columns we are considering. We will first try to simply perform a sort of winsorization on those values to the nearest value that we establish as \"the maximum\" we allow. As such, we simply set the values exceeding Â±0.3, to Â±0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns_to_plot:\n",
    "    snp[col] = snp[col].clip(upper=0.3, lower=-0.3)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(15, 10))\n",
    "for i, col in enumerate(columns_to_plot):\n",
    "    sns.boxplot(y=col, data=snp, ax=axes[i])\n",
    "    axes[i].set_title(f'Boxplot of {col}', fontsize=12)\n",
    "    axes[i].tick_params(axis='y', labelsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=5, ncols=1, figsize=(10, 10))\n",
    "\n",
    "columns_to_plot = ['LogReturns', 'LogReturnsDiv', 'DP', 'DE', 'EP']\n",
    "for i, col in enumerate(columns_to_plot):\n",
    "    axes[i].plot(snp['yyyymm'], snp[col], marker='', linestyle='-')\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel('Date')\n",
    "    axes[i].set_ylabel(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LAG CREATION AND SELECTION\n",
    "\n",
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACF and PACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_plot = ['LogReturns', 'LogReturnsDiv', 'DP', 'DE', 'EP']\n",
    "\n",
    "fig, axes = plt.subplots(10, 1, figsize=(10, 20))\n",
    "\n",
    "for i, col in enumerate(columns_to_plot):\n",
    "    acf_index = 2 * i\n",
    "    plot_acf(snp[col], lags = 100, alpha = 0.05, ax = axes[acf_index], title = f'ACF for {col}')\n",
    "    axes[acf_index].grid(True)\n",
    "    \n",
    "    pacf_index = 2 * i + 1\n",
    "    plot_pacf(snp[col], lags = 100, alpha = 0.05, ax = axes[pacf_index], title = f'PACF for {col}')\n",
    "    axes[pacf_index].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe how there is no clear patter in the ACF and PACF plots for most of the variables, so we will just start using an arbitrary number of lags and try different options from there. That being said, there is some lag correlation for DE and EP so those lags are probably going to be the most relevant, although with 5-10 lags we will already cover these correlations.\n",
    "\n",
    "Let's perform some causality tests to see how many lags we should consider for each variable. As we have already seen from the ACF and PACF that the maximum amount of relevant lags is less than 10, we will consider only 5 lags for each variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Granger Causality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_lags = snp.copy()\n",
    "snp_lags.drop(['Index', 'D12', 'E12', 'PriceDiv'], axis = 1, inplace = True)\n",
    "display(snp_lags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had to go with intervals longer than only a year for this exercise because the yearly rolling window would not allow us to have enough observations to perform some of the tests (for example the Granger causality test already only allows us to test up to 2 lags behind with the 12 observations of a yearly window).\n",
    "\n",
    "As a result, we decided to use windows of different eras more than just one year at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = [   [\"1927-01-01\", \"1932-12-01\"],\n",
    "                [\"1933-01-01\", \"1970-12-01\"],\n",
    "                [\"1971-01-01\", \"1997-12-01\"],\n",
    "                [\"1998-01-01\", \"2005-12-01\"],\n",
    "                [\"2006-01-01\", \"2021-11-01\"]]\n",
    "\n",
    "causality_tests = []\n",
    "\n",
    "for interval in intervals:\n",
    "    snp_temp = snp_lags[(snp_lags['yyyymm'] >= interval[0]) & (snp_lags['yyyymm'] <= interval[1])].dropna().reset_index(drop=True)\n",
    "    snp_temp = snp_temp.drop('yyyymm', axis = 1)\n",
    "    if interval == intervals[0]:\n",
    "        print(interval[0],' , ',interval[1],'\\n p = 5 \\n')\n",
    "    else:\n",
    "        print('\\n\\n',interval[0],' , ',interval[1],'\\n p = 5 \\n')\n",
    "    \n",
    "    print(\"\\n\\nFor lagged LogReturns\\n\", '#'*20)\n",
    "    result = grangercausalitytests(snp_temp[[\"LogReturns\", \"LogReturns\"]], 5)\n",
    "    causality_tests.append(result)\n",
    "    \n",
    "    print(\"\\n\\nFor lagged DP\\n\", '#'*20)\n",
    "    result = grangercausalitytests(snp_temp[[\"LogReturns\", \"DP\"]], 5)\n",
    "    causality_tests.append(result)\n",
    "    \n",
    "    print(\"\\n\\nFor lagged DE\\n\", '#'*20)\n",
    "    result = grangercausalitytests(snp_temp[[\"LogReturns\", \"DE\"]], 5)\n",
    "    causality_tests.append(result)\n",
    "    \n",
    "    print(\"\\n\\nFor lagged EP\\n\", '#'*20)\n",
    "    result = grangercausalitytests(snp_temp[[\"LogReturns\", \"EP\"]], 5)\n",
    "    causality_tests.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe how it appears that the EP ratio tends to be the most causal for LogReturns, especially in some periods more than others. Then we can also see that some lags of the DE ratio also pass the test (although only at a 10% confidence interval). As a result we are going to keep evaluating the lags to use, but we can probably safely try to use more than just 5 lags for DE and EP ratios.\n",
    "\n",
    "That being said, the results are not too surprising because the Dividends are just one component of the price, but a lot of people value more highly a stock which keeps its value and grows in price more than another stock which returns dividends but doesn't grow as much, because you can always resell the stock if needed.\n",
    "As a result, a company which is having consistent earnings is more probably higher valued than another with lower earnings and, as such, its price will probably be higher as well, hence this result. If a company does well one month, probably a lot of people will be at least a little bit more interested in buying their stock. The same can be said about an index like the S&P500. It's better to know that they are getting consistent and significant earnings more than knowing whether they paid dividends or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Correlation and Correlation among Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for interval in intervals:\n",
    "    snp_temp = snp_lags[(snp_lags['yyyymm'] >= interval[0]) & (snp_lags['yyyymm'] <= interval[1])].dropna()\n",
    "    snp_temp = snp_temp.drop(['yyyymm', 'LogReturns', 'LogReturnsDiv'], axis = 1)\n",
    "    if interval == intervals[0]:\n",
    "        print(interval[0],' , ',interval[1], '\\n', '#'*20)\n",
    "    else:\n",
    "        print('\\n\\n',interval[0],' , ',interval[1], '\\n', '#'*20)\n",
    "    \n",
    "    dp_de_correlation = dcor.distance_correlation(snp_temp['DP'], snp_temp['DE'])\n",
    "    dp_ep_correlation = dcor.distance_correlation(snp_temp['DP'], snp_temp['EP'])\n",
    "    de_ep_correlation = dcor.distance_correlation(snp_temp['DE'], snp_temp['EP'])\n",
    "    \n",
    "    print(\"Distance correlation between DP and DE:\", dp_de_correlation)\n",
    "    print(\"Distance correlation between DP and EP:\", dp_ep_correlation)\n",
    "    print(\"Distance correlation between DE and EP:\", de_ep_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for interval in intervals:\n",
    "    snp_temp = snp_lags[(snp_lags['yyyymm'] >= interval[0]) & (snp_lags['yyyymm'] <= interval[1])].dropna()\n",
    "    snp_temp = snp_temp.drop(['yyyymm', 'LogReturns', 'LogReturnsDiv'], axis = 1)\n",
    "    corr = snp_temp.corr()\n",
    "    display(corr.style.background_gradient(cmap='coolwarm', axis=None).format(\"{:.2f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lag Columns Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to conduct LASSO analysis, we have to already have the variables created. We have to create the lags for the variables so we will analyze up until 20 lags for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_corr_matrix = columns_to_plot.copy()\n",
    "\n",
    "for i in range(1, 11):\n",
    "    snp[f'Return_lag_{i}'] = snp['LogReturns'].shift(i)\n",
    "    # snp[f'ReturnsDiv_lag_{i}'] = snp['LogReturnsDiv'].shift(i)\n",
    "    snp[f'DP_lag_{i}'] = snp['DP'].shift(i)\n",
    "    snp[f'DE_lag_{i}'] = snp['DE'].shift(i)\n",
    "    snp[f'EP_lag_{i}'] = snp['EP'].shift(i)\n",
    "    \n",
    "    cols_corr_matrix.append(f'Return_lag_{i}')\n",
    "    # cols_corr_matrix.append(f'ReturnsDiv_lag_{i}')\n",
    "    cols_corr_matrix.append(f'DP_lag_{i}')\n",
    "    cols_corr_matrix.append(f'DE_lag_{i}')\n",
    "    cols_corr_matrix.append(f'EP_lag_{i}')\n",
    "\n",
    "display(snp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_corr = snp.copy()\n",
    "\n",
    "snp_corr = snp_corr.loc[(snp_corr['yyyymm'] >= '1927-01-01') & (snp_corr['yyyymm'] < '2022-01-01')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = snp_corr[cols_corr_matrix].corr()\n",
    "corr.style.background_gradient(cmap='coolwarm', axis=None).format(\"{:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how the Log Returns are not super correlated with anything but are actually a little bit correlated (less than 10%) with some things like some of its own lags and some lags of the DP and EP ratios as well. That being said, obviously we cannot really use the most correlated variables, which are the lag 0 ratios because they are directly computed using the Price so we would not have them in the actual period we will be trying to forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_lasso = snp.copy()\n",
    "\n",
    "snp_lasso.drop(['LogReturnsDiv', 'DP', 'DE', 'EP'], axis = 1, inplace = True)\n",
    "\n",
    "display(snp_lasso)\n",
    "\n",
    "for interval in intervals:\n",
    "    snp_temp = snp_lasso[(snp_lasso['yyyymm'] >= interval[0]) & (snp_lasso['yyyymm'] <= interval[1])].dropna().copy()\n",
    "    snp_temp = snp_temp.drop(['yyyymm'], axis = 1)\n",
    "    if interval == intervals[0]:\n",
    "        print(interval[0],' , ',interval[1], '\\n', '#'*20)\n",
    "    else:\n",
    "        print('\\n\\n',interval[0],' , ',interval[1], '\\n', '#'*20)\n",
    "    \n",
    "    y = snp_temp['LogReturns'].copy()\n",
    "    X = snp_temp.drop(['LogReturns'], axis = 1)\n",
    "    \n",
    "    lasso_model = Lasso(alpha=0.01)\n",
    "    lasso_model.fit(X, y)\n",
    "    print(\"Lasso coefficients:\", lasso_model.coef_)\n",
    "    print(\"Lasso intercept:\", lasso_model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teras Virta Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terasvirta_test(x, y):\n",
    "    model = Sequential()\n",
    "    input_dim = 1 if len(x.shape) == 1 else x.shape[1]\n",
    "    model.add(Dense(2, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(x, y, epochs=50, verbose=False)\n",
    "    \n",
    "    linear_model = Sequential()\n",
    "    linear_model.add(Dense(1, activation='linear'))\n",
    "    linear_model.compile(loss='mse', optimizer='sgd')\n",
    "    linear_model.fit(x, y, epochs=50, verbose=False)\n",
    "    pred_orig = linear_model.predict(x)\n",
    "    resid_orig = y.values - pred_orig\n",
    "    pred_nn = model.predict(x)\n",
    "    pred_nn = pred_nn.reshape(-1)\n",
    "    resid_nn = y.values - pred_nn\n",
    "    test_stat = np.mean(resid_orig**2 - resid_nn**2)\n",
    "    crit_val = chi2.ppf(0.95, 2)\n",
    "    if test_stat > crit_val:\n",
    "        print(\"The null hypothesis of linearity is rejected\")\n",
    "    else:\n",
    "        print(\"The null hypothesis of linearity is not rejected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_teras = snp.copy()\n",
    "\n",
    "snp_teras = snp_teras.loc[(snp_teras['yyyymm'] >= '1927-01-01') & (snp_teras['yyyymm'] < '2022-01-01')].reset_index(drop=True)\n",
    "\n",
    "for interval in intervals:\n",
    "    snp_temp = snp_teras[(snp_teras['yyyymm'] >= interval[0]) & (snp_teras['yyyymm'] <= interval[1])].dropna().copy()\n",
    "    snp_temp = snp_temp.drop(['yyyymm', 'LogReturnsDiv'], axis = 1)\n",
    "    if interval == intervals[0]:\n",
    "        print(interval[0],' , ',interval[1], '\\n', '#'*20)\n",
    "    else:\n",
    "        print('\\n\\n',interval[0],' , ',interval[1], '\\n', '#'*20)\n",
    "    \n",
    "    y = snp_temp['LogReturns'].copy()\n",
    "    X = snp_temp['DP'].copy()\n",
    "    \n",
    "    terasvirta_test(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for interval in intervals:\n",
    "    snp_temp = snp_teras[(snp_teras['yyyymm'] >= interval[0]) & (snp_teras['yyyymm'] <= interval[1])].dropna().copy()\n",
    "    snp_temp = snp_temp.drop(['yyyymm', 'LogReturnsDiv'], axis = 1)\n",
    "    if interval == intervals[0]:\n",
    "        print(interval[0],' , ',interval[1], '\\n', '#'*20)\n",
    "    else:\n",
    "        print('\\n\\n',interval[0],' , ',interval[1], '\\n', '#'*20)\n",
    "    \n",
    "    y = snp_temp['LogReturns'].copy()\n",
    "    X = snp_temp['DE'].copy()\n",
    "    \n",
    "    terasvirta_test(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for interval in intervals:\n",
    "    snp_temp = snp_teras[(snp_teras['yyyymm'] >= interval[0]) & (snp_teras['yyyymm'] <= interval[1])].dropna().copy()\n",
    "    snp_temp = snp_temp.drop(['yyyymm', 'LogReturnsDiv'], axis = 1)\n",
    "    if interval == intervals[0]:\n",
    "        print(interval[0],' , ',interval[1], '\\n', '#'*20)\n",
    "    else:\n",
    "        print('\\n\\n',interval[0],' , ',interval[1], '\\n', '#'*20)\n",
    "    \n",
    "    y = snp_temp['LogReturns'].copy()\n",
    "    X = snp_temp['EP'].copy()\n",
    "    \n",
    "    terasvirta_test(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['DP', 'DE', 'EP']:\n",
    "    snp_temp = snp_teras.dropna().copy()\n",
    "    if i == ['DP']:\n",
    "        print(i, '\\n', '#'*20)\n",
    "    else:\n",
    "        print('\\n\\n', i, '\\n', '#'*20)\n",
    "    \n",
    "    y = snp_temp['LogReturns'].copy()\n",
    "    X = snp_temp[i].copy()\n",
    "    \n",
    "    terasvirta_test(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ARIMA Baseline Model\n",
    "\n",
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp['yyyymm'] = pd.to_datetime(snp['yyyymm'])\n",
    "snp.set_index('yyyymm', inplace=True)\n",
    "snp.drop(['Index', 'D12', 'E12', 'PriceDiv', 'LogReturnsDiv'], axis = 1, inplace = True)\n",
    "\n",
    "snp_train = snp['1927-01-01':'2021-12-31']\n",
    "snp_test = snp['2022-01-01':]\n",
    "\n",
    "display(snp_train)\n",
    "display(snp_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_train_arima = snp_train.copy()\n",
    "snp_train_arima = snp_train_arima[['LogReturns', 'DP', 'DE', 'EP']]\n",
    "\n",
    "snp_test_arima = snp_test.copy()\n",
    "snp_test_arima = snp_test_arima[['LogReturns', 'DP', 'DE', 'EP']]\n",
    "\n",
    "model_auto_arima = pm.auto_arima(   snp_train_arima['LogReturns'], start_p=0, start_q=0,\n",
    "                                    test='adf',   \n",
    "                                    max_p=10, max_q=10,\n",
    "                                    m=1,         \n",
    "                                    d=None,      \n",
    "                                    seasonal=False, \n",
    "                                    start_P=0, \n",
    "                                    D=0, \n",
    "                                    trace=True,\n",
    "                                    error_action='ignore',  \n",
    "                                    suppress_warnings=True, \n",
    "                                    stepwise=True)\n",
    "\n",
    "print(model_auto_arima.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The auto arima function suggests a Moving Average model with 1 lag. We will instead try to fit an ARMA 1,1 model to the data as it is not entirely clear that the MA1 model really works better than the ARMA 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arima = ARIMA(snp_train_arima['LogReturns'], order=(1, 0, 1))\n",
    "model_arima_fit = model_arima.fit()\n",
    "\n",
    "arima_pred = model_arima_fit.get_forecast(steps=len(snp_test_arima))\n",
    "arima_pred_mean = arima_pred.predicted_mean\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# # plt.plot(snp_train_arima['LogReturns'], label='Training Data')\n",
    "# plt.plot(snp_test_arima['LogReturns'], label='Actual Returns')\n",
    "# plt.plot(arima_pred_mean.index, arima_pred_mean, label='ARIMA Predictions')\n",
    "# plt.legend()\n",
    "# plt.title('ARIMA Forecast versus Actuals')\n",
    "# plt.show()\n",
    "\n",
    "preds_plots = ModelPredictions(snp_test_arima['LogReturns'])\n",
    "preds_plots.add_predictions(arima_pred_mean, 'ARIMA')\n",
    "preds_plots.plot_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = PerformanceMetrics()\n",
    "metrics.add_metrics(snp_test_arima['LogReturns'], arima_pred_mean, name=\"ARIMA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. NEURAL NETWORK\n",
    "\n",
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = snp_train['LogReturns'].copy()\n",
    "X_tr = snp_train.drop(['LogReturns'], axis=1).copy()\n",
    "y_te = snp_test['LogReturns'].copy()\n",
    "X_te = snp_test.drop(['LogReturns'], axis=1).copy()\n",
    "\n",
    "words_to_search = ['Return', 'DE', 'lag'] \n",
    "# also tried with keeping all the columns and with only the returns but the results were worse.\n",
    "# best predictions were achieved when completely excluding DP and EP columns.\n",
    "# difference in performance when only taking lagged returns and when taking lagged returns with DE\n",
    "# with DE lags is not too significant.\n",
    "cols_to_use = [col for col in X_tr.columns if any(word in col for word in words_to_search)]\n",
    "\n",
    "X_tr = X_tr[cols_to_use]\n",
    "X_te = X_te[cols_to_use]\n",
    "\n",
    "y_valid = y_tr['2021-01-01':'2021-12-31'].copy()\n",
    "X_valid = X_tr['2021-01-01':'2021-12-31'].copy()\n",
    "y_train = y_tr['1927-01-01':'2020-12-31'].copy()\n",
    "X_train = X_tr['1927-01-01':'2020-12-31'].copy()\n",
    "\n",
    "display(y_train.head())\n",
    "display(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_te.values.reshape((X_te.shape[0], 1, X_te.shape[1]))\n",
    "X_valid = X_valid.values.reshape((X_valid.shape[0], 1, X_valid.shape[1]))\n",
    "\n",
    "display(X_train.shape)\n",
    "# display(X_train_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = Sequential([\n",
    "    Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    LSTM(64), # Tried 16, 50, 128\n",
    "    Dense(64, activation='relu'), # Tried 16, 32, 64\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "nn_model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "nn_model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = nn_model.fit(X_train, y_train, epochs=50, batch_size=2, validation_data=(X_valid, y_valid))#, callbacks=[early_stopping])\n",
    "# Tried batch size 2, 64, 128\n",
    "test_loss = nn_model.evaluate(X_test, y_te)\n",
    "print(f'Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Train and Valid Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nn = nn_model.predict(X_test)\n",
    "\n",
    "y_pred_nn_series = pd.Series(y_pred_nn.flatten(), index=y_te.index)\n",
    "preds_plots.add_predictions(y_pred_nn_series, 'LSTM')\n",
    "preds_plots.plot_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.add_metrics(y_te, y_pred_nn_series, name=\"LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. GAUSSIAN PROCESS\n",
    "\n",
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainGP = X_tr.copy()\n",
    "y_trainGP = y_tr.copy()\n",
    "X_testGP = X_te.copy()\n",
    "y_testGP = y_te.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_model = GaussianProcessRegressor(\n",
    "    kernel = C(), # Tried RBF and C kernels, both worked not so good.\n",
    "    alpha = 0.01 # Tried 0.001, 0.01. 0.1, 1.0, none of them worked well\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_model.fit(X_trainGP, y_trainGP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gp = gp_model.predict(X_testGP)\n",
    "y_pred_gp_series = pd.Series(y_pred_gp[0], index=y_testGP.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_plots.add_predictions(y_pred_gp_series, 'Gaussian Process')\n",
    "preds_plots.plot_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.add_metrics(y_testGP, y_pred_gp, name=\"Gaussian Process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOT IN USE, SAFEKEEPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def distance_matrix(vector):\n",
    "#     return np.abs(vector[:, None] - vector[None, :])\n",
    "\n",
    "# def distance_covariance(X, Y):\n",
    "#     n = X.shape[0]\n",
    "#     A = distance_matrix(X)\n",
    "#     B = distance_matrix(Y)\n",
    "#     A_mean = A.mean()\n",
    "#     B_mean = B.mean()\n",
    "#     A_centered = A - A_mean\n",
    "#     B_centered = B - B_mean\n",
    "#     dcov = np.sqrt((A_centered * B_centered).sum() / (n * n))\n",
    "#     return dcov\n",
    "\n",
    "# def distance_correlation(X, Y):\n",
    "#     dcov_XY = distance_covariance(X, Y)\n",
    "#     dcov_XX = distance_covariance(X, X)\n",
    "#     dcov_YY = distance_covariance(Y, Y)\n",
    "#     if dcov_XX * dcov_YY == 0:\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return dcov_XY / np.sqrt(dcov_XX * dcov_YY)\n",
    "\n",
    "# for interval in intervals:\n",
    "#     snp_temp = snp_lags[(snp_lags['yyyymm'] >= interval[0]) & (snp_lags['yyyymm'] <= interval[1])].dropna()\n",
    "#     snp_temp = snp_temp.drop(['yyyymm', 'LogReturns', 'LogReturnsDiv'], axis = 1)\n",
    "#     print('\\n\\n',interval[0],' , ',interval[1],'\\n', '#'*20)\n",
    "    \n",
    "#     dp_de_corr = distance_correlation(snp_temp['DP'].values, snp_temp['DE'].values)\n",
    "#     dp_ep_corr = distance_correlation(snp_temp['DP'].values, snp_temp['EP'].values)\n",
    "#     de_ep_corr = distance_correlation(snp_temp['DE'].values, snp_temp['EP'].values)\n",
    "    \n",
    "#     print(\"Distance correlation between DP and DE:\", dp_de_corr)\n",
    "#     print(\"Distance correlation between DP and EP:\", dp_ep_corr)\n",
    "#     print(\"Distance correlation between DE and EP:\", de_ep_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for interval in intervals:\n",
    "#     snp_temp = snp_lags[(snp_lags['yyyymm'] >= interval[0]) & (snp_lags['yyyymm'] <= interval[1])].dropna()\n",
    "#     snp_temp = snp_temp.drop(['yyyymm', 'LogReturns', 'LogReturnsDiv'], axis = 1)\n",
    "#     if interval == intervals[0]:\n",
    "#         print(interval[0],' , ',interval[1],'\\n', '#'*20)\n",
    "#     else:\n",
    "#         print('\\n\\n',interval[0],' , ',interval[1],'\\n', '#'*20)\n",
    "    \n",
    "#     dp_de_corr_dist = correlation(snp_temp['DP'].values, snp_temp['DE'].values)\n",
    "#     dp_ep_corr_dist = correlation(snp_temp['DP'].values, snp_temp['EP'].values)\n",
    "#     de_ep_corr_dist = correlation(snp_temp['DE'].values, snp_temp['EP'].values)\n",
    "    \n",
    "#     print(f\"Correlation distance between DP and DE: {dp_de_corr_dist}\")\n",
    "#     print(f\"Correlation distance between DP and EP: {dp_ep_corr_dist}\")\n",
    "#     print(f\"Correlation distance between DE and EP: {de_ep_corr_dist}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PerformanceMetrics:\n",
    "#     def __init__(self):\n",
    "#         self.metrics = {'R2': [], 'MSE': [], 'RMSE': [], 'MAE': []}\n",
    "#         self.set_names = []\n",
    "\n",
    "#     def add_metrics(self, r2, mse, rmse, mae, name=None):\n",
    "#         \"\"\"Add a new set of metrics to the storage with an optional name.\"\"\"\n",
    "#         if r2 >= 0:\n",
    "#             self.metrics['R2'].append(r2)\n",
    "#         else:\n",
    "#             self.metrics['R2'].append(0)\n",
    "#         self.metrics['MSE'].append(mse)\n",
    "#         self.metrics['RMSE'].append(rmse)\n",
    "#         self.metrics['MAE'].append(mae)\n",
    "#         if name is None:\n",
    "#             name = f\"Set {len(self.set_names) + 1}\"\n",
    "#         self.set_names.append(name)\n",
    "\n",
    "#     def plot_metrics(self):\n",
    "#         \"\"\"Plot all metrics in separate bar charts for comparison using set names for labels.\"\"\"\n",
    "#         n = len(self.metrics['MSE'])\n",
    "#         index = np.arange(n)\n",
    "#         bar_width = 0.35 \n",
    "#         color = 'skyblue'\n",
    "#         titles = {'R2': 'R2 Score', 'MSE': 'Mean Squared Error', 'RMSE': 'Root Mean Squared Error', 'MAE': 'Mean Absolute Error'}\n",
    "#         fig, axes = plt.subplots(nrows=4, ncols=1, figsize=(18, 18), sharey=True)\n",
    "#         for i, (metric_name, values) in enumerate(self.metrics.items()):\n",
    "#             axes[i].bar(index, values, bar_width, color=color, label=metric_name)\n",
    "#             axes[i].set_xlabel('Model Set')\n",
    "#             axes[i].set_title(titles[metric_name])\n",
    "#             axes[i].set_xticks(index)\n",
    "#             axes[i].set_xticklabels(self.set_names)\n",
    "#             axes[i].legend()\n",
    "#         plt.suptitle('Comparison of Performance Metrics')\n",
    "#         plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "#         plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralnets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
