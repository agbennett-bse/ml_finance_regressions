{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE 3:\n",
    "\n",
    "***Neural Networks and Gaussian process:***\n",
    "Predict the SP500 with the â€€nancial indicators assigned to your team in the google spreadsheet (ep, dp, de, dy, dfy, bm, svar, ntis, in, tbl , see RLab3 2 GWcausalSP500.R), some lagged series of these indicators and lags of the target using a Neural Network and a GP regression with your desired kernel. Predict return, or price, or direction (up or down). For which target works best? Do some feature selection to disregard some variables, select appropriate lags: causality, (distance) correlation, VAR-test, Lasso ... (The script RLab5 GausProc.R can be of help. The dataset is goyal-welch2022Monthly.csv and work within the period 1927/2021.)\n",
    "\n",
    "In our case, we have been assigned variables dp, de and ep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INDEX:\n",
    "\n",
    "0. [DATA AND LIBRARY IMPORTS](#0.-DATA-AND-LIBRARY-IMPORTS)\n",
    "\n",
    "1. [PREPROCESSING AND FEATURE ENGINEERING](#1.-PREPROCESSING-AND-FEATURE-ENGINEERING)\n",
    "\n",
    "2. [LAG CREATION AND SELECTION](#2.-LAG-CREATION-AND-SELECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. DATA AND LIBRARY IMPORTS\n",
    "\n",
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "from statsmodels.tsa.stattools import grangercausalitytests, adfuller, acf, pacf\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some further steps on the way down, we decided to keep the last period from 1926, as it will be useful for havig a value for the differenced variables straight from the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp = pd.read_csv('goyal-welch2022Monthly.csv')\n",
    "\n",
    "snp['yyyymm'] = snp['yyyymm'].astype(str)\n",
    "snp['yyyymm'] = pd.to_datetime(snp['yyyymm'], format='%Y%m')\n",
    "snp = snp.loc[(snp['yyyymm'] >= '1926-12-01') & (snp['yyyymm'] < '2022-01-01')].reset_index(drop=True)\n",
    "snp['Index'] = snp['Index'].str.replace(',', '').astype(float)\n",
    "\n",
    "display(snp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PREPROCESSING AND FEATURE ENGINEERING\n",
    "\n",
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that THERE ARE NO MISSING VALUES FOR OUR VARIABLES OF INTEREST (Index, D12 and E12)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the new features as we need to compute:\n",
    "\n",
    "- Dividend Price Ratio (DP)\n",
    "- Dividend Earnings Ratio (DE)\n",
    "- Earnings Price Ratio (EP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp = snp[['yyyymm', 'Index', 'D12', 'E12']]\n",
    "\n",
    "snp['LogReturns'] = np.log(snp['Index']).diff()\n",
    "snp['PriceDiv'] = snp['Index'] + snp['D12']\n",
    "snp['LogReturnsDiv'] = np.log(snp['PriceDiv']).diff()\n",
    "\n",
    "# We need to fill the NaN values with 0 because the ADF test doesn't tolerate NaN values and we might still need to further differentiate the series.\n",
    "snp.fillna({'LogReturns': 0}, inplace=True)\n",
    "snp.fillna({'LogReturnsDiv': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp['DP'] = np.log(snp['D12']) - np.log(snp['Index'])\n",
    "snp['DE'] = np.log(snp['D12']) - np.log(snp['E12'])\n",
    "snp['EP'] = np.log(snp['E12']) - np.log(snp['Index'])\n",
    "\n",
    "display(snp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=9, ncols=1, figsize=(10, 18))\n",
    "\n",
    "columns_to_plot = ['Index', 'PriceDiv', 'D12', 'E12', 'LogReturns', 'LogReturnsDiv', 'DP', 'DE', 'EP']\n",
    "for i, col in enumerate(columns_to_plot):\n",
    "    axes[i].plot(snp['yyyymm'], snp[col], marker='', linestyle='-')\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel('Date')\n",
    "    axes[i].set_ylabel(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We test for stationarity in the data\n",
    "\n",
    "for col in columns_to_plot:\n",
    "    adf_result = adfuller(snp[col])\n",
    "    print(f'ADF Statistic for {col}: {adf_result[0]}')\n",
    "    print(f'p-value for {col}: {adf_result[1]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables we are interested in are mostly stationary but there are a couple that should be further differenced in order to make them stationary.\n",
    "\n",
    "That being, said, log returns and log returns + dividends are already quite surely stationary so we're not going to bother with their stationarity anymore.\n",
    "\n",
    "Additionally, in further boxplots we have been able to see that variables DE and EP are quite skewed so, even if they are already decently stationary, we will also difference them in order to center them a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp['DP'] = snp['DP'].diff()\n",
    "snp['DE'] = snp['DE'].diff()\n",
    "snp['EP'] = snp['EP'].diff()\n",
    "\n",
    "display(snp.head())\n",
    "\n",
    "# We can safely remove the first row now instead of filling it with 0\n",
    "snp.dropna(axis = 0, inplace = True)\n",
    "\n",
    "display(snp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(10, 6))\n",
    "\n",
    "columns_to_plot = ['DP', 'DE', 'EP']\n",
    "for i, col in enumerate(columns_to_plot):\n",
    "    axes[i].plot(snp['yyyymm'], snp[col], marker='', linestyle='-')\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel('Date')\n",
    "    axes[i].set_ylabel(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# We test again for stationarity in the data\n",
    "\n",
    "for col in columns_to_plot:\n",
    "    adf_result = adfuller(snp[col])\n",
    "    print(f'ADF Statistic for {col}: {adf_result[0]}')\n",
    "    print(f'p-value for {col}: {adf_result[1]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how now our data is completely stationary and we may proceed. Careful attention to the outliers will be needed, though, as they are very specific to the 2008 crisis. We will first standardize the data and afterwards, if there are still outliers, we will treat them or maybe consider scaling with robust scaling (i.e. taking away the median instead of the mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_plot = ['LogReturns', 'LogReturnsDiv', 'DP', 'DE', 'EP']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(15, 10))\n",
    "for i, col in enumerate(columns_to_plot):\n",
    "    sns.boxplot(y=col, data=snp, ax=axes[i])\n",
    "    axes[i].set_title(f'Boxplot of {col}', fontsize=12)\n",
    "    axes[i].tick_params(axis='y', labelsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "snp_std = snp.copy()\n",
    "\n",
    "for col in columns_to_plot:\n",
    "    snp_std[col] = robust_scaler.fit_transform(snp_std[[col]])\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(15, 10))\n",
    "for i, col in enumerate(columns_to_plot):\n",
    "    sns.boxplot(y=col, data=snp, ax=axes[i])\n",
    "    axes[i].set_title(f'Boxplot of {col}', fontsize=12)\n",
    "    axes[i].tick_params(axis='y', labelsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe, the scaled version, even with the robust scaler, returns ranges which are still bigger than the range from the previous version. Even with the outliers we had, as we had already applied a logarithmic transformation to the data, the outliers were not excessively far away from the center, with the exception of the DE and EP ratios.\n",
    "\n",
    "What we will do is \"manually\" transform the data which is bigger than 0.3 in the five columns we are considering. We will first try to simply perform a sort of winsorization on those values to the nearest value that we establish as \"the maximum\" we allow. As such, we simply set the values exceeding Â±0.3, to Â±0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns_to_plot:\n",
    "    snp[col] = snp[col].clip(upper=0.3, lower=-0.3)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(15, 10))\n",
    "for i, col in enumerate(columns_to_plot):\n",
    "    sns.boxplot(y=col, data=snp, ax=axes[i])\n",
    "    axes[i].set_title(f'Boxplot of {col}', fontsize=12)\n",
    "    axes[i].tick_params(axis='y', labelsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=5, ncols=1, figsize=(10, 10))\n",
    "\n",
    "columns_to_plot = ['LogReturns', 'LogReturnsDiv', 'DP', 'DE', 'EP']\n",
    "for i, col in enumerate(columns_to_plot):\n",
    "    axes[i].plot(snp['yyyymm'], snp[col], marker='', linestyle='-')\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel('Date')\n",
    "    axes[i].set_ylabel(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LAG CREATION AND SELECTION\n",
    "\n",
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "plot_acf(snp['LogReturns'], lags=100, alpha=0.05, title='ACF for Series', ax=ax1)\n",
    "ax1.grid(True)\n",
    "\n",
    "plot_pacf(snp['LogReturns'], lags=100, alpha=0.05, title='PACF for Series', ax=ax2)\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe how there is no clear patter in the ACF and PACF plots, so we will just start using an arbitrary number of lags and try different options from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. NEURAL NETWORK\n",
    "\n",
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. GAUSSIAN PROCESS\n",
    "\n",
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Index](#INDEX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralnets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
